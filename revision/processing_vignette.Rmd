---
title: "Core Processing for scTAM-seq and EPI-clone"
author: "Michael Scherer & Lars Velten"
date: "09/27/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ComplexHeatmap)
library(viridis)
library(ggplot2)
library(plyr)
library(Seurat)
library(reshape2)
library(doParallel)
library(slingshot)
library(scanalysis)
plot_theme_legend <- theme(panel.background = element_rect(color='black',fill='white'),
                          panel.grid=element_blank(),
                          text=element_text(color='black',size=10),
                          axis.text=element_text(color='black',size=10),
                          axis.ticks=element_line(color='black', size=.1),
                          strip.background = element_blank(),
                          legend.key=element_rect(color='black', fill=NA),
                          legend.key.size = unit(5, 'mm'),
                          strip.text = element_text(color='black',size=12))
source('scripts/helper_functions.R')
```

This vignette processes all the counts matrices obtained with scTAM-seq to generate a final Seurat object, which can be used for further exploration.

## Create Seurat objects individually

For all of the samples (i.e., scTAM-seq runs) individually, we first read in the count matrices, remove the doublets and perform simple dimension reduction.

```{r seutp_paths, warning=F, message=F}
larry1 <- 'LARRY_mouse1'
larry2 <- 'LARRY_mouse2'
larry3 <- 'LARRY_mouse3'
larry4 <- 'LARRY_mouse4'
lk_stained <- 'LK_LSK_stained'
lk_unstained <- 'LK_LSK_unstained'
wildtype <- 'LK_WT_stained'
names_long <- c(larry1, larry2, larry3, larry4, lk_stained, lk_unstained, wildtype)
names_short <- c('larry1', 'larry2', 'larry3', 'larry4', 'stained', 'unstained', 'WT_LKs')
names(names_short) <- names_long
protein_available <- c('stained', 'larry3', 'larry4', 'WT_LKs')
experiments <- c(rep('LARRY main experiment', 4), rep('LARRY replicate', 2), 'Native Hematopoieis')
names(experiments) <- names_long
# Path to the download directory from GEO
data_path <- 'GEO/' 
panel_file <- "infos/panel_info_dropout_pwm.tsv"
out_path <- '~'
```

Then, we read-in the uncut experiment to determine which amplicons successfully worked.

```{r select_amplicons}
selected_amplicons <- read.table(panel_file,
                               header=T)
selected_amplicons <- selected_amplicons[selected_amplicons$DropoutUncutLKs>0.9, ]
non_hha <- row.names(selected_amplicons[selected_amplicons$Type%in%'Non_cut', ])
colinfo <- selected_amplicons[selected_amplicons$Type%in%c("HSC_high",
                                                           "MPPI_high",
                                                           "MPPII_high",
                                                           "MPP_high", 
                                                           "IMR",
                                                           "WSH"), ]
dmr_amplicons <- row.names(selected_amplicons[selected_amplicons$Type%in%c("HSC_high",
                                                                           "MPPI_high",
                                                                           "MPPII_high",
                                                                           "MPP_high"), ])

```

Next, we read in each of the scTAM-seq runs individually and create a Seurat object.

```{r import, message=FALSE, warning=FALSE}
obj_list <- lapply(names_long, function(name){
  rowinfo <- read.csv(paste0(data_path, name, "_doublet_scores_DoubletDetection.csv"),
                      row.names = 2)
  rowinfo <- rowinfo[which(rowinfo$DoubletDetectionLabel==0), ]
  if(names_short[name]%in%protein_available){
    prot_data <- read.table(paste0(data_path, name, '-umi-counts.tsv.gz'),
                            header=TRUE)
    prot_data <- prot_data[prot_data$cell_barcode%in%row.names(rowinfo), ]
    prot_data <- split(prot_data, prot_data$ab_barcode_description)
    for(j in 1:length(prot_data)){
      x <- prot_data[[j]]
      row.names(x) <- x$cell_barcode
      ab_counts <- x[row.names(rowinfo), 'umi_count']
      ab_name <-gsub('_totalseqb', '', unique(x[, 'ab_barcode_description'])) 
      rowinfo[, paste0(ab_name, '_raw')] <- ab_counts
    }
  }
  filtered.counts <- read.table(paste0(data_path,
                                       name,
                                       ".barcode.cell.distribution.tsv"),
                                row.names = 1, header=T)
  filtered.counts <- filtered.counts[row.names(rowinfo), ]
  rowinfo$PerformanceNonHhaI <- apply(ifelse(filtered.counts[row.names(rowinfo), non_hha]>0,1,0), 1, mean)
  rowinfo$Nfeatures <- apply(filtered.counts[, row.names(selected_amplicons)], 1, function(x){
    sum(x>0)
  })
  rowinfo$NReads <- rowSums(filtered.counts[, row.names(selected_amplicons)])
  rowinfo$Sample <- name
  row.names(rowinfo) <- paste0(row.names(rowinfo), '_', names_short[name])
  row.names(filtered.counts) <- paste0(row.names(filtered.counts), '_', names_short[name])
  selected_amplicons <- row.names(colinfo)
  selected_data <- ifelse(filtered.counts[row.names(rowinfo), selected_amplicons]>0, 1, 0)
  clust <- cutree(hclust(dist(selected_data, 'binary'),
                         'ward.D2'), 3)
  rowinfo$InitialClustering <- as.factor(clust)
  top_anno <- HeatmapAnnotation(df=subset(rowinfo, select = c('InitialClustering',
                                                              'Sample',
                                                              'PerformanceNonHhaI',
                                                              'DoubletDetectionLabel')),
                                annotation_legend_param = list(title_gp = gpar(fontsize = 20, fontface = "bold"),
                                                               labels_gp = gpar(fontsize = 20)),
                                gp = gpar(fontsize = 25),
                                na_col = 'white')
  left_anno <- HeatmapAnnotation(df=subset(colinfo, select = c("HSC_mean",
                                                               "MPP1_mean",
                                                               "MPP2_mean",
                                                               "MPP_mean",
                                                               "Type")),
                                 annotation_legend_param = list(title_gp = gpar(fontsize = 20, fontface = "bold"),
                                                                labels_gp = gpar(fontsize = 20)),
                                 gp = gpar(fontsize = 25),
                                 na_col = 'white',
                                 which='row')
  png(file.path(out_path, paste0('heatmap_', names_short[name], '.png')),
      width=1600,
      height=1000)
  p <- ComplexHeatmap::Heatmap(t(selected_data), 
                          left_annotation = left_anno,
                          top_annotation = top_anno,
                          clustering_distance_columns = "binary", 
                          clustering_distance_rows = "binary",
                          show_row_names = F, 
                          show_column_names = F, 
                          clustering_method_columns = "ward.D2",
                          clustering_method_rows = "ward.D2",
                          col=rev(inferno(50)),
                          column_split = 3,
                          show_heatmap_legend = FALSE)
  draw(p)
  dev.off()
  
  rowinfo$HSCClustering <- rowinfo$InitialClustering
  write.csv(rowinfo, file.path(out_path, paste0('rowinfo_', names_short[name], '.csv')))
  write.csv(selected_data, file.path(out_path, paste0('heatmap_data', names_short[name], '.csv')))
  seurat.obj <- CreateSeuratObject(t(selected_data),
                                   assay = "DNAm",
                                   meta.data = rowinfo)
  seurat.obj <- ScaleData(seurat.obj,
                          features = dmr_amplicons)
  seurat.obj <- RunPCA(seurat.obj,
                       npcs = 200,
                       features=dmr_amplicons)
  seurat.obj <- FindNeighbors(seurat.obj,
                              dims = 1:ifelse(name=='LK_WT_stained', 11, 8))
  seurat.obj <- FindClusters(seurat.obj,
                             resolution = 0.5)
  seurat.obj <- RunUMAP(seurat.obj,
                        dims = 1:ifelse(name=='LK_WT_stained', 11, 8))
  saveRDS(seurat.obj, file.path(out_path, paste0("DNAm_seurat_", names_short[name], ".RDS")))
  seurat.obj
})
names(obj_list) <- names_long
```

## Integration with Seurat's IntegrateData function

To overcome batch effects, we used Seurat's `IntegrateData` function, using each of the samples as a batch on its own.

```{r integration, message=FALSE, warning=FALSE}
integration_features <- SelectIntegrationFeatures(obj_list[c('LK_WT_stained',
                                                                       'LK_LSK_stained',
                                                                       'LK_LSK_unstained',
                                                                       paste0('LARRY_mouse', 1:4))])
integration_anchors <- FindIntegrationAnchors(object.list = obj_list[c('LK_WT_stained',
                                                                       'LK_LSK_stained',
                                                                       'LK_LSK_unstained',
                                                                       paste0('LARRY_mouse', 1:4))],
                                              anchor.features = integration_features)
seurat_combined <- IntegrateData(anchorset=integration_anchors)
rowinfo <- seurat_combined[[]]
seurat_ab <- CreateAssayObject(counts = t(rowinfo[, colnames(rowinfo)[grepl('_raw', colnames(rowinfo))]]))
seurat_ab <- NormalizeData(seurat_ab, 
                            normalization.method = 'CLR',
                            assay='AB')
seurat_combined[['AB']] <- seurat_ab
saveRDS(seurat_combined, file.path(out_path, "EPI_clone_seurat.RDS"))
```

## Anntotating and clustering the LARRY barcodes

For some of the samples, LARRY lentiviral barcoding was used to associate each cell to a clone. Since we found clonal barcode complexity to be quite high, we additionally performed clustering and merging of LARRY barcodes. Briefly, a clustering based on the pairwise Jaccard index of clonal barcodes is performed. The clustering cutoff is determined based on a permutation test. We perform clonal clustering for both LARRY batches individually.

```{r clonal_annotation}
get_overlap <- function(binary1, binary2) {
  sum(binary1&binary2) / (sum(binary1) + sum(binary2) - sum(binary1&binary2))  #this seems to be jaccard similarity
}
get_clone <- function(read_vector, barcode_vector, clonal_groups) {
  #for each cell determine how many reads support each clone (from the clustering)
  df <- data.frame(used_barcodes = barcode_vector[read_vector >0 ],
                   used_reads =read_vector[read_vector >0 ],
                   clonal_group = clonal_groups[barcode_vector[read_vector >0 ]])
  df.sum <- ddply(df, "clonal_group", summarise, nreads = sum(used_reads))
  df.sum <- df.sum[order(df.sum$nreads, decreasing = T),]
  data.frame(clone = df.sum[1,"clonal_group"], reads_support = df.sum[1,"nreads"], reads_dev = sum(df.sum[-1,"nreads"]), other_clones = paste(df.sum[-1,"clonal_group"], collapse = ";"))
}
simulate <- function(ncells_clone1,ncells_clone2, ncells_total, fn, fp, nrep = 1000) {
  replicate(nrep, {
    cellids <- 1:ncells_total
    c1 <- sample(cellids, ncells_clone1)
    cellids <- cellids[!cellids%in%c1]
    c2 <- sample(cellids, ncells_clone2)
    
    v1 <- runif(ncells_total) < fp
    v2 <- runif(ncells_total) < fp
    
    v1[c1] <- runif(ncells_clone1) > fn
    v2[c2] <- runif(ncells_clone2) > fn
    
    get_overlap(v1,v2)
  })
  
}

all_max_clones <- c()
all_clones <- lapply(c('LARRY main experiment', 'LARRY replicate'), function(batch){
  all_larry <- read.csv(paste0(data_path, ifelse(batch=='LARRY main experiment', 'LARRY_main', 'LARRY_replicate'), '_larry.csv'),
                        header=F,
                        col.names = c("Cell","LARRY","Reads"))
  all_larry$Cell <- gsub("[\\(\\)\\']","", all_larry$Cell)
  all_larry$LARRY <- gsub("[\\(\\)\\' ]","", all_larry$LARRY)
  all_larry$LARRY <- all_larry$LARRY
  all_larry$batch <- batch
  all_larry$Sample <- sapply(strsplit(all_larry$Cell, '_'), function(x)x[2])

  sel_samples <- names(experiments)[which(experiments==batch)]
  scTAMseq <- subset(seurat_combined, Sample%in%sel_samples)
  larry_matrix_all <- acast(all_larry, LARRY~Cell,value.var="Reads", fill = 0)
  
  # determine the jaccard index between any pair of LARRY barcodes. 
  larry_bcs <- rownames(larry_matrix_all)
  overlap <- sapply(larry_bcs, function(x){
    sapply(larry_bcs, function(y) get_overlap(larry_matrix_all[x,]>0,larry_matrix_all[y,]>0))
  })
  #4 perform clustering and visualization using pheatmap

  clustering.distance <- as.dist(1-overlap)
  
  annof <- ddply(all_larry, c("Sample","LARRY"), summarise, nCells = as.numeric(length(Reads) > 0))
  annof <- as.data.frame(acast(annof, LARRY ~ Sample, value.var = "nCells", fill = 0))
  cl <- pheatmap::pheatmap(overlap, show_rownames = F, show_colnames = F, annotation_col = annof, clustering_method = "ward.D2", clustering_distance_rows = clustering.distance, clustering_distance_cols = clustering.distance)
  clonal_group <- cutree(cl$tree_col, h = 0.95) 
  annof$clone <- clonal_group
  dev.off()
  png(file.path(out_path, paste0("clones_heatmap_", batch, "_jaccard.png")), width=4800,height=4500)
  pheatmap(overlap, show_rownames = F, show_colnames = F, annotation_col = annof, 
           clustering_method = "ward.D2", clustering_distance_rows = clustering.distance, clustering_distance_cols = clustering.distance)
  dev.off()

  #5. Determine what LARRY clusters are significant, and which ones are just spurious (e.g. by false positives)
  #for each clonal group in the basic clustering, determine how many cells there are. Then determine if the observed jaccard index/indeces
  #are expected from technical noise or significant.
  
  #5a. Estimate false negative rate: Fraction of cells that should have a LARRY barcode but don't
  #.   Note: it is not quite correct. In reality the FNR is higher, because the MoI was > 0.
  #.   I have a script somewhere to jointly estimate FNR and MoI from similar data using a likelihood approach
  #.   But FNR does not seem to be the most critical parameter to determine if the clusters are significant. FPR is more important.
  fn <- 1-ncol(larry_matrix_all)/length(Cells(scTAMseq))
  
  #5b. Estimate false positive rate
  #.   An empricial estimate could be: How often do cells of clone X (in the basic clustering)
  #.   have another barcode observed that does not belong to the clone main?
  #.   Again this is not maybe super stringent but it should give an idea?
  
  clones <- apply(larry_matrix_all, 2, get_clone, barcode_vector = rownames(larry_matrix_all), clonal_groups = clonal_group, simplify = F)
  clones <- do.call(rbind, clones)
  
  fp <- mean(clones$reads_dev > 0)
  
  
  #5d. Test each observed putative clone, if it could have arisen by chance
  test_each_clonalgroup <- mclapply(unique(clonal_group), function(id) { 
    barcodes <- names(clonal_group)[clonal_group == id]
    if (length(barcodes)==1) return(1) 
    cells <- subset(all_larry, LARRY%in%barcodes)
    ncells_byclone <- table(cells$LARRY)
    observed_jacard <- overlap[barcodes,barcodes]
    pvals <- unlist(lapply(1:(length(barcodes)-1), function(x) {
      lapply((x+1):length(barcodes), function(y) {
        mean(observed_jacard[x,y] < simulate(round(ncells_byclone[x]/(1-fn)), round(ncells_byclone[y]/(1-fn)),  length(Cells(scTAMseq)), fn, fp))
        #as clone size estimate, naively correct using the estimated fn?
      })
    }))
    
    #how do I aggregate this into one p value???
    data.frame(mean.p = mean(pvals), min.p = min(pvals), n.sig = sum(pvals < 0.05))
  
  }, mc.cores = 6)
  
  #5e. Summarise some statistics on the clonal groups
  clonal_group_stats <- data.frame(id = unique(clonal_group),
                                   do.call(rbind, test_each_clonalgroup),
                                   mean_overlap = sapply(unique(clonal_group), function(id) {
                                     barcodes <- names(clonal_group)[clonal_group == id]
                                     observed_jacard <- overlap[barcodes,barcodes]
                                     mean(observed_jacard[upper.tri(observed_jacard)])
                                   }),
                                   nbarcodes = sapply(unique(clonal_group), function(x) sum(clonal_group==x)),
                                   ncells = sapply(unique(clonal_group), function(id) {
                                     barcodes <- names(clonal_group)[clonal_group == id]
                                     cells <- subset(all_larry, LARRY%in% barcodes)
                                     length(unique(cells$Cell))
                                   }))
  
  #5f. Save compute-heavy results
  save(overlap, clonal_group_stats, file = file.path(out_path, paste0("jaccard_", batch, ".rda")))
  
  #5g. For "signficant" clones, use the clone from the clustering, for the others, LARRY Barcode = Clone
  selected <- clonal_group_stats$id[which(clonal_group_stats$min.p < 0.001)]
  new.clonal_group <- ifelse(clonal_group %in%selected, clonal_group, names(clonal_group))
  names(new.clonal_group) <- names(clonal_group)
  saveRDS(new.clonal_group, file.path(out_path, paste0("new.clonal_group", batch, ".RDS")))
  
  #6. Assign cells to clones, uses the get_clone function already defined in step 5b
  
  final.clones <- apply(larry_matrix_all, 2, get_clone, barcode_vector = rownames(larry_matrix_all), clonal_groups = new.clonal_group, simplify = F)
  final.clones <- do.call(rbind, final.clones)
  final.clones$dev_ratio <- final.clones$reads_dev / (final.clones$reads_support + final.clones$reads_dev)

  final.clones$sample <- unlist(sapply(row.names(final.clones), function(x)unlist(strsplit(x, '_'))[2]))
  ggplot(final.clones, aes(x=sample, y=dev_ratio))+geom_boxplot()
  final.clones$cleanClone <- ifelse(final.clones$reads_support > 3 & final.clones$dev_ratio < ifelse(batch=='LARRY replicate', 0.75, 0.3), paste0(final.clones$clone, ifelse(batch=='LARRY main experiment', '_main', '_replicate')), NA)
  final.clones
})
all_clones <- do.call('rbind', all_clones)
seurat_combined <- AddMetaData(seurat_combined, all_clones)
all_max_clones <- c()
for(batch in c('LARRY main experiment', 'LARRY replicate')){
  all_larry <- read.csv(paste0(data_path, ifelse(batch=='LARRY main experiment', 'LARRY_main', 'LARRY_replicate'), '_larry.csv'),
                        header=F,
                        col.names = c("Cell","LARRY","Reads"))
  all_larry$Cell <- gsub("[\\(\\)\\']","", all_larry$Cell)
  all_larry$LARRY <- gsub("[\\(\\)\\' ]","", all_larry$LARRY)
  all_larry$LARRY <- paste0(all_larry$LARRY, ifelse(batch=='LARRY main experiment', '_main', '_replicate'))
  all_larry$batch <- batch
  all_larry$Sample <- sapply(strsplit(all_larry$Cell, '_'), function(x)x[2])

  sel_samples <- names(experiments)[which(experiments==batch)]
  scTAMseq <- subset(seurat_combined, Sample%in%sel_samples)
  rowinfo <- scTAMseq[[]]
  max_clones <- rep(NA, nrow(rowinfo))
  names(max_clones) <- row.names(rowinfo)
  clone_barcode_count <- rep(NA, nrow(rowinfo))
  names(clone_barcode_count) <- row.names(rowinfo)
  for(barcode in unique(all_larry$Cell)){
    selected <- all_larry[all_larry$Cell%in%barcode,,drop=FALSE]
    clone_barcode_count[barcode] <- nrow(selected)
    max_clones[unique(selected$Cell)] <- selected$LARRY[which.max(selected$Reads)]
  }
  all_max_clones <- c(all_max_clones, max_clones)
}
seurat_combined$LARRY <- all_max_clones
rowinfo <- seurat_combined[[]]
rowinfo$FinalClone <- NA
for(clone in unique(rowinfo$cleanClone)){
  if(is.na(clone)) next
  if(nchar(clone)>15){
    rowinfo[which(rowinfo$cleanClone%in%clone), 'FinalClone'] <- clone
  }else{
    selected_cells <- rowinfo[which(rowinfo$cleanClone%in%clone), ]
    max_max_clone <- plyr::count(selected_cells$LARRY)
    rowinfo[which(rowinfo$cleanClone%in%clone), 'FinalClone'] <- max_max_clone[which.max(max_max_clone$freq), 'x']
  }
}
seurat_combined$FinalClone <- rowinfo$FinalClone
saveRDS(seurat_combined, file.path(out_path, "EPI_clone_seurat.RDS"))
```

## Cell type annotation

As a last step, we identify cell types in our data using the expression of surface markers and cluster-specific methylation profiles.

```{r cluster_annotation}
DefaultAssay(seurat_combined) <- "integrated"
seurat_combined <- ScaleData(seurat_combined)
seurat_combined <- RunPCA(seurat_combined,
                          npcs = 30)
ElbowPlot(seurat_combined)
seurat_combined <- RunUMAP(seurat_combined,
                           reduction = "pca",
                           dims = 1:8)
seurat_combined <- FindNeighbors(seurat_combined)
seurat_combined <- FindClusters(seurat_combined,
                                resolution = 0.5)
seurat_combined[['umap']]@cell.embeddings[ , 'UMAP_1'] <- -seurat_combined[['umap']]@cell.embeddings[ , 'UMAP_1']
DimPlot(seurat_combined,
  reduction = "umap",
  label=TRUE)
ggsave(file.path(out_path, 'seurat_clusters.png'))
# We remove points in low density areas of the UMAP
rem_points <- ifelse(seurat_combined[['umap']]@cell.embeddings[ , 'UMAP_1']>1&
                       seurat_combined[['umap']]@cell.embeddings[ , 'UMAP_1']<2.5&
                       seurat_combined[['umap']]@cell.embeddings[ , 'UMAP_2']>4.5,
                     "Singleton", "Other")
seurat_combined$Singleton <- rem_points
DimPlot(seurat_combined,
  group.by = "Singleton",
  reduction = "umap",
  label=TRUE)
to_plot <- seurat_combined[[]]
ggplot(to_plot, aes(x=Singleton, y=DoubletDetectionScore))+geom_boxplot()
seurat_combined <- subset(seurat_combined, subset = Singleton=='Other')
rem_points <- ifelse(seurat_combined[['umap']]@cell.embeddings[ , 'UMAP_1']>1&
                       seurat_combined$seurat_clusters%in%c('6', '7'),
                     "Singleton", "Other")
seurat_combined$Singleton <- rem_points
DimPlot(seurat_combined,
        group.by = "Singleton",
        reduction = "umap",
        label=TRUE)
seurat_combined <- subset(seurat_combined, subset = Singleton=='Other')

panel <- read.table(panel_file, sep='\t')
seurat_combined$CellType <- NA
cluster_2 <- differential_test(seurat_combined, ident.1 = '2')
cluster_2 <- run_marker_enrichment(cluster_2, panel, fc.cut = 0)
seurat_combined$CellType[seurat_combined$seurat_clusters%in%c('2')] <- 'EryP'
cluster_4 <- differential_test(seurat_combined, ident.1 = '4')
cluster_4 <- run_marker_enrichment(cluster_4, panel, fc.cut = 0)
seurat_combined$CellType[seurat_combined$seurat_clusters%in%c('4')] <- 'MEP'
seurat_combined$CellType[seurat_combined$seurat_clusters%in%c('1', '8', '0')] <- 'GMP'
seurat_combined$CellType[seurat_combined$seurat_clusters%in%c('5')] <- 'pre/pro-B'
seurat_combined$CellType[seurat_combined$seurat_clusters%in%c('6', '7')] <- 'HSC/MPP1'
```

Some of the clusters that were identified still require further investigation and annotation.

```{r subclusters, message=FALSE, warning=FALSE}
seurat_combined <- FindNeighbors(seurat_combined)
seurat_combined <- FindSubCluster(seurat_combined,
                                  cluster='3',
                                  graph.name = 'integrated_nn',
                                  resolution = 0.25)
adt_data <- data.frame(sub.cluster=seurat_combined$sub.cluster, t(GetAssayData(seurat_combined, slot='data', assay='AB')))
ggplot(adt_data, aes(x=sub.cluster, y=CD135.raw))+geom_boxplot()
ggplot(adt_data, aes(x=sub.cluster, y=SCA1.raw))+geom_boxplot()
seurat_combined$CellType[seurat_combined$sub.cluster%in%c('3_1')] <- 'MPP3'
seurat_combined$CellType[seurat_combined$sub.cluster%in%c('3_0')] <- 'MPP4'
seurat_combined <- FindSubCluster(seurat_combined,
                                  cluster='6',
                                  graph.name = 'integrated_nn',
                                  resolution = 0.75)
seurat_combined$CellType[seurat_combined$sub.cluster%in%c('6_0', '6_1')] <- 'HSC/MPP1'
seurat_combined$CellType[seurat_combined$sub.cluster%in%c('6_2', '6_4')] <- 'MPP3'
seurat_combined$CellType[seurat_combined$sub.cluster%in%c('6_3')] <- 'MPP2'
DimPlot(seurat_combined,
        group.by = 'sub.cluster')

seurat_hscs <- subset(seurat_combined, CellType=='HSC/MPP1')
seurat_hscs <- FindNeighbors(seurat_hscs)
seurat_hscs <- FindClusters(seurat_hscs, resolution = 0.1)
cells <- seurat_combined$CellType
cells[Cells(seurat_hscs)] <- paste0('HSC', seurat_hscs$seurat_clusters)
cells[cells=='HSC0'] <- 'HSC/MPP1'
cells[cells=='HSC1'] <- 'MkP 1'
cells[cells=='HSC2'] <- 'MkP 2'
seurat_combined$CellType <- cells
seurat.hsc1 <- subset(seurat_hscs, subset=seurat_clusters=='1')
seurat.hsc1 <- FindNeighbors(seurat.hsc1)
seurat.hsc1 <- FindClusters(seurat.hsc1)
DimPlot(seurat.hsc1)

rem_cells <- Cells(seurat.hsc1)[seurat.hsc1$seurat_clusters%in%c('2', '1')]
seurat_combined <- seurat_combined[, !(Cells(seurat_combined)%in%rem_cells)]
saveRDS(seurat_combined, file.path(out_path, "EPI_clone_seurat.RDS"))
```

## Pseudotime analysis

As a last step, we perform Pseudotime analysis using slingshot and annotate the corresponding pseudotimes in the final Seurat object.

```{r pseudotime, message=FALSE, warning=FALSE}
Idents(seurat_combined) <- 'CellType'
hscs <- names(Idents(seurat_combined)[Idents(seurat_combined)%in%'HSC/MPP1'])
seurat_mono <- seurat_to_sce(seurat_combined, default_assay='DNAm')
seurat_mono <- slingshot(seurat_mono,
                         clusterLabels = 'CellType',
                         reducedDim = 'PCA',
                         start.clus='HSC/MPP1')
pseudotime <- slingPseudotime(seurat_mono, na=TRUE)
pseudotime <- as.data.frame(pseudotime)
colnames(pseudotime) <- c('erythroid pseudotime', 'myeloid pseudotime', 'B cell pseudotime', 'MkP pseudotime')
pseudotime$Pseudotime <- rowMeans(pseudotime[, 1:3], na.rm=T)
seurat_combined <- AddMetaData(seurat_combined, pseudotime)
```

## Cleanup metadata

```{r cleanup}
rowinfo <- seurat_combined[[]]
clone_counts <- plyr::count(na.omit(rowinfo$FinalClone))
rowinfo$CloneCount <- NA
for(cl in clone_counts$x){
  rowinfo[rowinfo$FinalClone%in%cl, 'CloneCount'] <- clone_counts[clone_counts$x%in%cl, 'freq']
}
rowinfo <- rowinfo[, c('Sample', 'PerformanceNonHhaI', 'nFeature_DNAm', 'CellType', 'FinalClone', 'CloneCount', 'Pseudotime')]
colnames(rowinfo) <- c('ProcessingBatch', 'PerformanceNonHhaI', 'nFeature_DNAm', 'CellType', 'LARRY', 'LARRYSize', 'Pseudotime')
rowinfo$Experiment <- experiments[rowinfo$ProcessingBatch]
rowinfo$Fluorophore <- substr(rowinfo$LARRY, 1, 6)
seurat_combined@meta.data <- rowinfo
saveRDS(seurat_combined, file.path(out_path, "EPI_clone_seurat.RDS"))
```